test_R[, niter]
# How does the Rcpp version do?
test_Rcpp <- EM_Rcpp(rs=samps[ , 1:500], t=samps[1, 501:750], w=samps[2, 751:1000],
cov=cov, niter=niter)
# Estimate at last iteration
test_Rcpp[, niter]
microbenchmark(
method = EM_R(rs=samps[ , 1:500], t=samps[1, 501:750], w=samps[2, 751:1000],
cov=cov, niter=niter),
generic = EM_Rcpp(rs=samps[ , 1:500], t=samps[1, 501:750], w=samps[2, 751:1000],
cov=cov, niter=niter),
times = 100L
)
microbenchmark(
R_version = EM_R(rs=samps[ , 1:500], t=samps[1, 501:750], w=samps[2, 751:1000],
cov=cov, niter=niter),
Rcpp_version = EM_Rcpp(rs=samps[ , 1:500], t=samps[1, 501:750], w=samps[2, 751:1000],
cov=cov, niter=niter),
times = 100L
)
hist(rnorm(1000, mean=0, sd=rgamma(n=1000, shape=1, rate=0.5)))
hist(rnorm(10000, mean=0, sd=rgamma(n=10000, shape=1, rate=0.5)))
hist(rnorm(10000, mean=0, sd=rgamma(n=10000, shape=1, rate=0.5)),breaks=-10:10)
hist(rnorm(10000, mean=0, sd=rgamma(n=10000, shape=1, rate=0.5)),breaks=-10:10, xlim=c(-10,10))
hist(rnorm(10000, mean=0, sd=rgamma(n=10000, shape=1, rate=0.5)),breaks=-9:9, xlim=c(-10,10))
hist(rnorm(10000, mean=0, sd=rgamma(n=10000, shape=1, rate=0.5)), xlim=c(-10,10), breaks=-9:9)
hist(rnorm(10000, mean=0, sd=rgamma(n=10000, shape=1, rate=0.5)), breaks=-50:50)
hist(rnorm(10000, mean=0, sd=rgamma(n=10000, shape=1, rate=2)), breaks=-50:50)
hist(rnorm(10000, mean=0, sd=rgamma(n=10000, shape=1, rate=1/2)), breaks=-50:50)
hist(rnorm(10000, mean=0, sd=rgamma(n=10000, shape=1, rate=1/2)), breaks=-50:50, freq=FALSE)
hist(rnorm(1000, mean=0, sd=sqrt(rexp(1000, rate=2))))
hist(rnorm(1000, mean=0, sd=sqrt(rexp(1000, rate=2))), breaks=-5:5)
hist(rnorm(1000, mean=0, sd=sqrt(rexp(1000, rate=2))), breaks=seq(from=-5, to=5, by=0.1))
hist(rnorm(10000, mean=0, sd=sqrt(rexp(10000, rate=2))), breaks=seq(from=-5, to=5, by=0.1))
hist(rnorm(100000, mean=0, sd=sqrt(rexp(100000, rate=2))), breaks=seq(from=-5, to=5, by=0.1))
hist(rnorm(100000, mean=0, sd=sqrt(rexp(100000, rate=2))), breaks=seq(from=-10, to=10, by=0.1))
install.packages("rmutil")
library("rmutil", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
plot(-10:10, dlaplace(-10:10))
plot(seq(from=-10, to=10, by=0.1), dlaplace(seq(from=-10, to=10, by=0.1)))
hist(rnorm(100000, mean=0, sd=sqrt(rexp(100000, rate=2))), breaks=seq(from=-10, to=10, by=0.1))
plot(seq(from=-10, to=10, by=0.1), dlaplace(seq(from=-10, to=10, by=0.1)), add=TRUE)
curve(dlaplace(x),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
hist(rnorm(100000, mean=0, sd=sqrt(rexp(100000, rate=2))), breaks=seq(from=-10, to=10, by=0.1))
curve(dlaplace(x),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
hist(rnorm(100000, mean=0, sd=sqrt(rexp(100000, rate=2))), breaks=seq(from=-10, to=10, by=0.1), freq=FALSE)
curve(dlaplace(x),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
rlaplace(10000)
hist(rlaplace(10000), freq=FALSE)
hist(rlaplace(10000), freq=FALSE,breaks=seq(from=-10, to=10, by=0.1))
hist(rnorm(100000, mean=0, sd=sqrt(rexp(100000, rate=2))), breaks=seq(from=-10, to=10, by=0.1), freq=FALSE)
curve(function(x)=exp((1-x)/(-2x))*x^(-3/2)*(1-x)^(-1/2), from=0.01, to=0.99)
curve(function(x){exp((1-x)/(-2x))*x^(-3/2)*(1-x)^(-1/2)}, from=0.01, to=0.99)
prof=function(x){exp((1-x)/(-2x))*x^(-3/2)*(1-x)^(-1/2)}
2^4
exp((1-3)/(-23))
curve(function(x){exp((1-x)/(-2*x))*x^(-3/2)*(1-x)^(-1/2)}, from=0.01, to=0.99)
curve(Vectorize(function(x){exp((1-x)/(-2*x))*x^(-3/2)*(1-x)^(-1/2)}), from=0.01, to=0.99)
curve(function(x){exp((1-x)/(-2*x))*x^(-3/2)*(1-x)^(-1/2)}, from=0.01, to=0.99)
prof=function(x){exp((1-x)/(-2*x))*x^(-3/2)*(1-x)^(-1/2)}
prof(0)
prof(1)
prof(0/001)
prof(0/0.1)
prof(0/0.2)
prof(0/0.3)
prof(0.3)
prof(0)
prof(0.1)
prof(1)
prof(0.9)
prof(0.001
)
prof(seq(from=0.01, to=0.99, by=0.01))
prof(0.99)
plot(seq(from=0.01, to=0.99, by=0.01), prof(seq(from=0.01, to=0.99, by=0.01)))
plot(seq(from=0.001, to=0.999, by=0.001), prof(seq(from=0.001, to=0.999, by=0.001)))
load("~/Downloads/Jon/INLA_Horseshoe/Simulations/it_works.RData")
choose(3,2)
combn(9,2)
t(combn(9,2))
load("~/Downloads/RA/bias_project/simulations/sim_results_4_chain.RData")
load("~/Downloads/RA/bias_project/stan_fits/select_stan_fits_restrict.RData")
library(INLA)
inla.list.models()
inla.doc("rw2d")
load("~/Downloads/Mauricio/Hierarchical_Partitions/bayesian-multifile-record-linkage/testing/test_data_500_dup_simulations_pois_blocked.RData")
load("~/Downloads/Jon_Mauricio/CRC_Simulations/more_kosovo_stuff.RData")
exp(8.49)
exp(8.6)
exp(8.7)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
remove.packages("rstan")
exp(100)
exp(101)
exp(200)
exp(1000)
exp(500)
install.packages("bayesplot")
install.packages("bindr")
install.packages("bindrcpp")
install.packages("INLA", repos=c(getOption("repos"), INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
install.packages("devtools")
library(devtools)
install_github("julianfaraway/brinla")
install.packages("broom")
install.packages("tidyverse")
install.packages("clubSandwich")
install.packages("coda")
install.packages("cowplot")
install.packages("data.table")
install.packages("dga")
install.packages("faraway")
install.packages("geepack")
install.packages("gee")
install.packages("geoR")
install.packages("ggfortify")
install.packages("glmnet")
install.packages("igraph")
install.packages("INLABMA")
install.packages("KMsurv")
install.packages("knitr")
install.packages("lattice")
install.packages("latticeExtra")
install.packages("LCMCR")
install.packages("mcclust")
install.packages("microbenchmark")
install.packages("remotes")
install.packages("remotes")
emotes::install_github("bernardsilverman/modslavmse")
remotes::install_github("bernardsilverman/modslavmse")
install.packages("SparseMSE")
install.packages("mvtnorm")
install.packages("nlme")
install.packages("parallel")
install.packages("partitions")
install.packages("raster")
install.packages("RcppArmadillo")
install.packages("RcppParallel")
install.packages("readr")
install.packages("RecordLinkage")
install.packages("rgeos")
install.packages("rjags")
install.packages("rmarkdown")
remove.packages("rstan")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
install.packages("SpatialEpi")
install.packages("spatstat")
install.packages("stargazer")
install.packages("survey")
install.packages("survminer")
install.packages("SUMMER")
devtools::install_github("bryandmartin/SUMMER")
devtools::install_github("bryandmartin/SUMMER", build_vignettes=T)
install.packages("R.rsp")
devtools::install_github("bryandmartin/SUMMER", build_vignettes=T)
browseVignettes("SUMMER")
install.packages("INLA", repos=c(getOption("repos"), INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
INLA::inla.list.models()
INLA::inla.doc("cbinomial")
install.packages("INLA", repos=c(getOption("repos"), INLA="https://inla.r-inla-download.org/R/testing"), dep=TRUE)
install.packages("INLA", repos=c(getOption("repos"), INLA="https://inla.r-inla-download.org/R/testing"), dep=TRUE)
INLA::inla.doc("betabinomialna")
library(SUMMER)
data(KenData)
UN <- KenData$IGME2019
View(UN)
replace(c(1, NA, 2, NA), is.na(c(1, NA, 2, NA)), "Missing")
1
2
3
23
24
25
26
27
38
load("~/Downloads/Mauricio/Hierarchical_Partitions/bayesian-multifile-record-linkage/simulations/no_dup_sim_results/no_dup_sim_results_tidy.RData")
View(results)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/dup_example_records.RData")
records <- as.data.frame(apply(records, 2, as.character)[, 2:8], stringsAsFactors = FALSE)
break_list <- list(NA, c(0, 0.25, 0.5), c(0, 0.25, 0.5), c(0, 0.25, 0.5), c(0, 0.25, 0.5), NA, NA)
file_sizes <- c(424, 419, 394)
comparison_list <- create_comparison_data(records,
c("bi", "lv", "lv", "lv", "lv", "bi", "bi"),
break_list, 3, file_sizes,
duplicates = c(1, 1, 1))
library(multilink)
comparison_list <- create_comparison_data(records,
c("bi", "lv", "lv", "lv", "lv", "bi", "bi"),
break_list, 3, file_sizes,
duplicates = c(1, 1, 1))
sum(c(424, 419, 394))
comparison_list <- create_comparison_data(records,
c("bi", "lv", "lv", "lv", "lv", "bi", "bi"),
break_list, 3, file_sizes,
duplicates = c(1, 1, 1))
nrow(records)
nrow(records)==sum(c(424, 419, 394))
file_sizes <- c(424, 419, 394)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/dup_example_records.RData")
records <- as.data.frame(apply(records, 2, as.character)[, 2:8], stringsAsFactors = FALSE)
break_list <- list(NA, c(0, 0.25, 0.5), c(0, 0.25, 0.5), c(0, 0.25, 0.5), c(0, 0.25, 0.5), NA, NA)
file_sizes <- c(424, 419, 394)
comparison_list <- create_comparison_data(records,
c("bi", "lv", "lv", "lv", "lv", "bi", "bi"),
break_list, 3, file_sizes,
duplicates = c(1, 1, 1))
comparison_list <- create_comparison_data(records,
c("bi", "lv", "lv", "lv", "lv", "bi", "bi"),
break_list, file_sizes, K = 3,
duplicates = c(1, 1, 1))
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/abex.RData")
sum(ab_full != comparison_list$ab)
keep <- (comparison_list$comparisons[, 6] != TRUE) &
(comparison_list$comparisons[, 10] != TRUE)
reduced_comparison_list <- reduce_comparison_data(comparison_list, keep, cc = 1)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/cckeep.RData")
sum(cc_keep!= reduced_comparison_list$pairs_to_keep)
prior_list <- specify_prior(reduced_comparison_list, mus = NA, nus = NA,
flat = 0, alphas = rep(1, 7),
dup_upper_bound = c(10, 10, 10),
dup_count_prior_family = c("Poisson", "Poisson", "Poisson"),
dup_count_prior_pars = list(c(1), c(1), c(1)),
n_prior_family = "uniform",
n_prior_pars = NA)
dups_cc_blocked <- gibbs_sampler(reduced_comparison_list, prior_list, seed = 42)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/resdupex.RData")
sum(dups_cc_blocked$partitions!=dups_to_save$partitions)
sum(dups_cc_blocked$contingency_tables!=dups_to_save$contingency_tables)
sum(dups_cc_blocked$match_samp!=dups_to_save$match_samp)
sum(dups_cc_blocked$non_match_samp!=dups_to_save$non_match_samp)
reduced_comparison_list_nocc <- reduce_comparison_data(comparison_list, keep, cc = 0)
prior_list_nocc <- specify_prior(reduced_comparison_list_nocc, mus = NA, nus = NA,
flat = 0, alphas = rep(1, 7),
dup_upper_bound = c(10, 10, 10),
dup_count_prior_family = c("Poisson", "Poisson", "Poisson"),
dup_count_prior_pars = list(c(1), c(1), c(1)),
n_prior_family = "uniform",
n_prior_pars = NA)
dups_nocc_blocked <- gibbs_sampler(reduced_comparison_list_nocc, prior_list_nocc, seed = 42)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/resdupex2.RData")
sum(dups_nocc_blocked$partitions!=dups_blocked$partitions)
sum(dups_nocc_blocked$contingency_tables!=dups_blocked$contingency_tables)
sum(dups_nocc_blocked$match_samp!=dups_blocked$match_samp)
sum(dups_nocc_blocked$non_match_samp!=dups_blocked$non_match_samp)
prior_list_flat <- specify_prior(reduced_comparison_list, flat = 1)
prior_list_nocc_flat <- specify_prior(reduced_comparison_list_nocc, flat = 1)
dups_cc_blocked_flat <- gibbs_sampler(reduced_comparison_list, prior_list_flat, seed = 42)
dups_nocc_blocked_flat <- gibbs_sampler(reduced_comparison_list_nocc, prior_list_nocc_flat, seed = 42)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/resdupex3.RData")
sum(dups_cc_blocked_flat$partitions!=dups_flat_to_save$partitions)
sum(dups_cc_blocked_flat$contingency_tables!=dups_flat_to_save$contingency_tables)
sum(dups_cc_blocked_flat$match_samp!=dups_flat_to_save$match_samp)
sum(dups_cc_blocked_flat$non_match_samp!=dups_flat_to_save$non_match_samp)
sum(dups_nocc_blocked_flat$partitions!=dups_blocked_flat$partitions)
sum(dups_nocc_blocked_flat$contingency_tables!=dups_blocked_flat$contingency_tables)
sum(dups_nocc_blocked_flat$match_samp!=dups_blocked_flat$match_samp)
sum(dups_nocc_blocked_flat$non_match_samp!=dups_blocked_flat$non_match_samp)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/nodup_example_records.RData")
records <- as.data.frame(apply(records, 2, as.character)[, 2:8], stringsAsFactors = FALSE)
break_list <- list(NA, c(0, 0.25, 0.5), c(0, 0.25, 0.5), c(0, 0.25, 0.5), c(0, 0.25, 0.5), NA, NA)
file_sizes <- c(264, 255, 237)
comparison_list <- create_comparison_data(records,
c("bi", "lv", "lv", "lv", "lv", "bi", "bi"),
break_list, file_sizes, K = 3,
duplicates = c(0, 0, 0))
prior_list <- specify_prior(comparison_list, mus = NA, nus = NA,
flat = 0, alphas = rep(1, 7),
dup_upper_bound = c(1, 1, 1),
dup_count_prior_family = NA,
dup_count_prior_pars = NA,
n_prior_family = "uniform",
n_prior_pars = NA)
no_dups <- gibbs_sampler(comparison_list, prior_list, seed = 42)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/resnodupex.RData")
sum(no_dups$partitions!=no_dups_tosave$partitions)
sum(no_dups$contingency_tables!=no_dups_tosave$contingency_tables)
sum(no_dups$match_samp!=no_dups_tosave$match_samp)
sum(no_dups$non_match_samp!=no_dups_tosave$non_match_samp)
no_dups_pe <- find_bayes_estimate(no_dups$partitions, 100,  max_cc_size = 50)
no_dups_partialpe <- find_bayes_estimate(no_dups$partitions, 100,  L_A = 0.1,
max_cc_size = 10)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/nodupspe.RData")
sum(no_dups_pe!=Z_hat)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/nodupspartial.RData")
sum(no_dups_partialpe!=partial_Z_hat)
sum(no_dups$partitions!=no_dups_tosave$partitions)
sum(no_dups$contingency_tables!=no_dups_tosave$contingency_tables)
sum(no_dups$match_samp!=no_dups_tosave$match_samp)
sum(no_dups$non_match_samp!=no_dups_tosave$non_match_samp)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/nodupspe.RData")
sum(no_dups_pe!=Z_hat)
no_dups_pe <- find_bayes_estimate(no_dups$partitions, 100,  max_cc_size = 50)
sum(no_dups_pe!=Z_hat)
no_dups_pe
Z_hat
sum(no_dups$partitions!=no_dups_tosave$partitions)
sum(no_dups$contingency_tables!=no_dups_tosave$contingency_tables)
sum(no_dups$match_samp!=no_dups_tosave$match_samp)
sum(no_dups$non_match_samp!=no_dups_tosave$non_match_samp)
prior_list_flat <- specify_prior(comparison_list, flat = 1)
no_dups_flat <- gibbs_sampler(comparison_list, prior_list_flat, seed = 42)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/resnodupex2.RData")
sum(no_dups_flat$partitions!=no_dups_flat_tosave$partitions)
sum(no_dups_flat$contingency_tables!=no_dups_flat_tosave$contingency_tables)
sum(no_dups_flat$match_samp!=no_dups_flat_tosave$match_samp)
sum(no_dups_flat$non_match_samp!=no_dups_flat_tosave$non_match_samp)
no_dups_pe <- find_bayes_estimate(no_dups$partitions, burn_in = 100,  max_cc_size = 50)
sum(no_dups_pe!=Z_hat)
sum(no_dups$partitions!=no_dups_tosave$partitions)
sum(no_dups_flat$partitions!=no_dups_flat_tosave$partitions)
sum(no_dups_flat$contingency_tables!=no_dups_flat_tosave$contingency_tables)
sum(no_dups_flat$match_samp!=no_dups_flat_tosave$match_samp)
sum(no_dups_flat$non_match_samp!=no_dups_flat_tosave$non_match_samp)
keep <- (comparison_list$comparisons[, 6] != TRUE) &
(comparison_list$comparisons[, 10] != TRUE)
Z_init <- initialize_partition(comparison_list, keep, seed = 42)
load("~/Downloads/Mauricio/Project_1/bayesian-multifile-record-linkage/examples/resnodupex3.RData")
sum(Z_init != Z_init_ts)
no_dups_Z_init <- gibbs_sampler(comparison_list, prior_list, seed = 42,
Z_init = Z_init)
load("~/Downloads/Analysis/R/Rwanda/Rwanda_cluster_dat.rda")
View(mod.dat)
table(mod.dat$years, mod.dat$survey)
load("~/Downloads/Rwanda_cluster_dat.rda")
table(mod.dat$years, mod.dat$survey)
load("~/Downloads/Analysis/R/Rwanda/Rwanda_cluster_dat.rda")
table(mod.dat$years, mod.dat$survey)
View(mod.dat)
load("~/Downloads/Mauricio/Project_1/Paper_Simulations_For_Submission/results/no_dup_error_sim_results/no_dup_error_sim_results_point_estimates.RData")
View(results)
load("~/Downloads/Mauricio/Project_1/Paper_Simulations_For_Submission/results/dup_sim_results/dup_sim_results_point_estimates.RData")
View(results)
library(dplyr)
library(ggplot2)
library(ggridges)
library(ggpubr)
library(forcats)
library(xtable)
# Load helper functions
source("helper_functions.R")
# Load posterior samples for N
load("nhoi_fits/N_samples_sensitivity.RData")
# Hyperparameters for prior for N
M <- c(8000, 12000, 10000)
a <- c(43, 9, 1.6)
N_lcmcr <- N_lcmcr %>% mutate(interaction = as.factor(interaction))
xis <- c(1 / 2, 2 / 3, 1, 3 / 2, 2)
priors <- c("NB(8000, 43)", "NB(12000, 9)", "NB(10000, 1.6)",
"Improper Scale Prior")
N_lcmcr$which <- "Posterior"
for(i in 1:length(M)){
temp <- data.frame(N = n_0_sampler_nbinom(rep(1, 100000), M = M[i],
a = a[i], n = 0),
prior = i, which = "Prior")
for(j in 1:length(xis)){
temp$interaction <- xis[j]
N_lcmcr  <- rbind(N_lcmcr , temp)
}
}
N_lcmcr$prior <- as.factor(N_lcmcr$prior)
priors <- c("NB(8000, 43)", "NB(12000, 9)", "NB(10000, 1.6)",
"Improper Scale Prior")
levels(N_lcmcr$prior) <- priors
N_lcmcr <- N_lcmcr %>%
mutate(prior = fct_relevel(prior, rev(priors)))
N_lcmcr$interaction <- factor(N_lcmcr$interaction, levels = xis,
ordered = TRUE,
labels = c(expression(paste(xi , " = ", "1 / 2")),
expression(paste(xi , " = ", "2 / 3")),
expression(paste(xi , " = ", "1")),
expression(paste(xi , " = ", "3 / 2")),
expression(paste(xi , " = ", "2"))))
N_lcmcr %>%
mutate(which = fct_relevel(as.factor(which), c("Prior", "Posterior"))) %>%
ggplot(aes(x = N, fill = which)) + geom_density(alpha = 0.5) +
theme_bw() +
# facet_grid(rows = vars(interaction), cols = vars(prior)) +
facet_grid(interaction ~ prior,
labeller = labeller(interaction = label_parsed)) +
xlim(0, 45000) + theme(legend.position = "top") +
labs(y = "Density", fill = "Prior or Posterior?")
ggsave("plots/sensitivity_analysis_nhoi_plot1.pdf", height = 7, width = 8, units = "in")
priors <- c("Improper Scale Prior", "Negative-Binomial", "NB(12000, 9)",
"NB(8000, 43)")
levels(N_lcmcr$prior) <- priors
N_lcmcr %>%
mutate(which = fct_relevel(as.factor(which), c("Prior", "Posterior"))) %>%
filter(which == "Posterior", prior %in% c("Negative-Binomial",
"Improper Scale Prior")) %>%
ggplot(aes(x = N)) +
geom_density(aes(linetype = prior), alpha = 0.5) +
theme_bw() +
facet_grid(cols = vars(interaction),
labeller = labeller(interaction = label_parsed)) +
scale_x_continuous(name = "N", limits = c(0, 55000),
breaks = c(0, 10000, 30000, 50000)) +
theme(legend.position = "top") +
labs(y = "Density", linetype = "Prior for N")
ggsave("plots/sensitivity_analysis_nhoi_plot2.pdf", height = 4, width = 8, units = "in")
N_lcmcr %>%
mutate(which = fct_relevel(as.factor(which), c("Prior", "Posterior"))) %>%
filter(which == "Posterior", prior %in% c("Negative-Binomial")) %>%
ggplot(aes(x = N)) +
geom_density(alpha = 0.5) +
theme_bw() +
facet_grid(cols = vars(interaction),
labeller = labeller(interaction = label_parsed)) +
scale_x_continuous(name = "N", limits = c(0, 50000),
breaks = c(0, 10000, 30000, 50000)) +
labs(y = "Density", linetype = "Prior for N")
ggsave("plots/sensitivity_analysis_nhoi_plot3.pdf", height = 4, width = 8, units = "in")
levels(N_lcmcr$interaction) <- c("1 / 2", "2 / 3", "1", "3 / 2", "2")
setwd("~/Downloads/Jon_Mauricio/Project_2/Code/Paper_Application")
library(dplyr)
library(ggplot2)
library(ggridges)
library(ggpubr)
library(forcats)
library(xtable)
# Load helper functions
source("helper_functions.R")
# Load posterior samples for N
load("nhoi_fits/N_samples_sensitivity.RData")
# Hyperparameters for prior for N
M <- c(8000, 12000, 10000)
a <- c(43, 9, 1.6)
N_lcmcr <- N_lcmcr %>% mutate(interaction = as.factor(interaction))
xis <- c(1 / 2, 2 / 3, 1, 3 / 2, 2)
priors <- c("NB(8000, 43)", "NB(12000, 9)", "NB(10000, 1.6)",
"Improper Scale Prior")
N_lcmcr$which <- "Posterior"
for(i in 1:length(M)){
temp <- data.frame(N = n_0_sampler_nbinom(rep(1, 100000), M = M[i],
a = a[i], n = 0),
prior = i, which = "Prior")
for(j in 1:length(xis)){
temp$interaction <- xis[j]
N_lcmcr  <- rbind(N_lcmcr , temp)
}
}
N_lcmcr$prior <- as.factor(N_lcmcr$prior)
priors <- c("NB(8000, 43)", "NB(12000, 9)", "NB(10000, 1.6)",
"Improper Scale Prior")
levels(N_lcmcr$prior) <- priors
N_lcmcr <- N_lcmcr %>%
mutate(prior = fct_relevel(prior, rev(priors)))
N_lcmcr$interaction <- factor(N_lcmcr$interaction, levels = xis,
ordered = TRUE,
labels = c(expression(paste(xi , " = ", "1 / 2")),
expression(paste(xi , " = ", "2 / 3")),
expression(paste(xi , " = ", "1")),
expression(paste(xi , " = ", "3 / 2")),
expression(paste(xi , " = ", "2"))))
N_lcmcr %>%
mutate(which = fct_relevel(as.factor(which), c("Prior", "Posterior"))) %>%
ggplot(aes(x = N, fill = which)) + geom_density(alpha = 0.5) +
theme_bw() +
# facet_grid(rows = vars(interaction), cols = vars(prior)) +
facet_grid(interaction ~ prior,
labeller = labeller(interaction = label_parsed)) +
xlim(0, 45000) + theme(legend.position = "top") +
labs(y = "Density", fill = "Prior or Posterior?")
ggsave("plots/sensitivity_analysis_nhoi_plot1.pdf", height = 7, width = 8, units = "in")
priors <- c("Improper Scale Prior", "Negative-Binomial", "NB(12000, 9)",
"NB(8000, 43)")
levels(N_lcmcr$prior) <- priors
N_lcmcr %>%
mutate(which = fct_relevel(as.factor(which), c("Prior", "Posterior"))) %>%
filter(which == "Posterior", prior %in% c("Negative-Binomial",
"Improper Scale Prior")) %>%
ggplot(aes(x = N)) +
geom_density(aes(linetype = prior), alpha = 0.5) +
theme_bw() +
facet_grid(cols = vars(interaction),
labeller = labeller(interaction = label_parsed)) +
scale_x_continuous(name = "N", limits = c(0, 55000),
breaks = c(0, 10000, 30000, 50000)) +
theme(legend.position = "top") +
labs(y = "Density", linetype = "Prior for N")
ggsave("plots/sensitivity_analysis_nhoi_plot2.pdf", height = 4, width = 8, units = "in")
N_lcmcr %>%
mutate(which = fct_relevel(as.factor(which), c("Prior", "Posterior"))) %>%
filter(which == "Posterior", prior %in% c("Negative-Binomial")) %>%
ggplot(aes(x = N)) +
geom_density(alpha = 0.5) +
theme_bw() +
facet_grid(cols = vars(interaction),
labeller = labeller(interaction = label_parsed)) +
scale_x_continuous(name = "N", limits = c(0, 50000),
breaks = c(0, 10000, 30000, 50000)) +
labs(y = "Density", linetype = "Prior for N")
ggsave("plots/sensitivity_analysis_nhoi_plot3.pdf", height = 4, width = 8, units = "in")
levels(N_lcmcr$interaction) <- c("1 / 2", "2 / 3", "1", "3 / 2", "2")
N_lcmcr %>%
mutate(which = fct_relevel(as.factor(which), c("Prior", "Posterior")),
) %>%
filter(which == "Posterior", prior %in% c("Negative-Binomial")) %>%
ggplot(aes(x = N)) +
geom_density(aes(color = interaction), alpha = 0.5) +
theme_bw() +
#facet_grid(cols = vars(interaction),  labeller = labeller(interaction = label_parsed)) +
scale_x_continuous(name = "N", limits = c(0, 45000),
breaks = c(0, 15000, 30000, 45000)) +
#  theme(legend.position = "top") +
labs(y = "Density", linetype = expression(xi))
ggsave("plots/sensitivity_analysis_nhoi_plot4.pdf", height = 4, width = 6, units = "in")
